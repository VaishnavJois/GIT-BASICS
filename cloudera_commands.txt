*******Root************
hdfs dfs -mkdir /test1/
*******Desktop command*******
gedit ss4.txt
hdfs dfs -put ss4.txt /test1/
hdfs dfs -ls /test1
hdfs dfs -cat /test1/ss4.txt
hdfs dfs -get /test1/ss4.txt ss5.txt
cd /usr/lib/hadoop-mapreduce
yarn jar hadoop-mapreduce-examples.jar wordcount /test1/ss4.txt /test2/


////////////////////////


javac -cp `hadoop classpath` WordCount.java

javac -cp `hadoop classpath` -d wordcount_classes WordCount.java

sudo tar -xvf <path to .gz>

hdfs dfsadmin -safemode leave

//////////////////////////

**inside wordcount_classes

  javac -cp /usr/lib/hadoop/*:/usr/lib/hadoop-mapreduce/* WordCount.java

  jar -cvf wordcount.jar *.class

  sudo cp wordcount.jar /usr/lib/hadoop-mapreduce/

hdfs dfs -mkdir /test6
gedit vv.txt
hdfs dfs -put vv.txt /test6/


  hadoop jar wordcount.jar WordCount /test6/vv.txt /test7

hdfs dfs -ls /test7/

hdfs dfs -get /test7/part-r-00000

**
NOTE
::::test6-----war-and-peace-input
::::test7-----war-and-peace-output
///////////////


*******hadoop streaming********

chmod u+x program_name

echo "foo foo quux labs foo bar quux" | ./mapper.py

echo "foo foo quux labs foo bar quux" | ./mapper.py|sort -k1,1

echo "foo foo quux labs foo bar quux" | ./mapper.py|sort -k1,1|./reducer.py


hadoop jar /usr/hdp/current/hadoop-mapreduce-client/hadoop-streaming.jar -file ./mapper.py -mapper ./mapper.py -file ./reducer.py -reducer ./reducer.py -input war-and-peace-input/war-and-peace.txt -output war-and-peace-output


hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar -file ./mapper.py -mapper ./mapper.py -file ./reducer.py -reducer ./reducer.py -input /test6/vv.txt -output /test8
















































































